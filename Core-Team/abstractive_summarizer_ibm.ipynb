{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enc_dec_summarizer",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "giT-5ASe_C8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E32KxzGEkz-",
        "colab_type": "code",
        "outputId": "3e25050d-6646-47ce-a30b-4ba7e4456b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgLkgP6__HIq",
        "colab_type": "code",
        "outputId": "974a64d9-5b87-49ae-bf00-0d99baba5be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlITgXYtdcfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = pd.read_csv('/content/drive/My Drive/Amazon_Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3bTxQWdcbt",
        "colab_type": "code",
        "outputId": "3f35f1f7-918d-4e40-fd63-6bbe261b7da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "reviews_df['Score'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    363122\n",
              "4     80655\n",
              "1     52268\n",
              "3     42640\n",
              "2     29769\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRxNV7EudcXr",
        "colab_type": "code",
        "outputId": "7575de74-b1b9-445f-b5d0-7fde500ad95c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "neg_df = reviews_df[reviews_df['Score'] <= 4].sample(20000, random_state=15)\n",
        "\n",
        "neg_df = neg_df.dropna(subset=['Summary'])\n",
        "\n",
        "neg_df.head()"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>215069</th>\n",
              "      <td>215070</td>\n",
              "      <td>B0030VBRCG</td>\n",
              "      <td>A3GVWQSH9KRU14</td>\n",
              "      <td>mom of a foodie kid</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1300406400</td>\n",
              "      <td>SUPER SOUR!!!</td>\n",
              "      <td>My 5.5 yr old son LOVES apricots and sweet pot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205060</th>\n",
              "      <td>205061</td>\n",
              "      <td>B0002PHFKQ</td>\n",
              "      <td>AJU5NCWYOM5T2</td>\n",
              "      <td>Beatriz V. Austin</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1325548800</td>\n",
              "      <td>Orange flower taste in a bottle</td>\n",
              "      <td>This orange flower water is pretty good. You h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287143</th>\n",
              "      <td>287144</td>\n",
              "      <td>B000EMK4VE</td>\n",
              "      <td>A1JY64GQC3B8WV</td>\n",
              "      <td>R. Davis</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1222473600</td>\n",
              "      <td>Ok, but it is just tea</td>\n",
              "      <td>Tea is not just flavored colored water. Now th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174199</th>\n",
              "      <td>174200</td>\n",
              "      <td>B000LL0RKG</td>\n",
              "      <td>A3CJ63L7LVTH53</td>\n",
              "      <td>Michelle</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>1186185600</td>\n",
              "      <td>Delicious and Convenient -- No Waste!</td>\n",
              "      <td>I like Silk soymilk because it stays fresh in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215811</th>\n",
              "      <td>215812</td>\n",
              "      <td>B002Z04ZNQ</td>\n",
              "      <td>A3CT3C010B9BBY</td>\n",
              "      <td>James L. Bimler</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1302134400</td>\n",
              "      <td>First time Coconut juice taster</td>\n",
              "      <td>I wasn't really sure what to expect here. I'm ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  ...                                               Text\n",
              "215069  215070  ...  My 5.5 yr old son LOVES apricots and sweet pot...\n",
              "205060  205061  ...  This orange flower water is pretty good. You h...\n",
              "287143  287144  ...  Tea is not just flavored colored water. Now th...\n",
              "174199  174200  ...  I like Silk soymilk because it stays fresh in ...\n",
              "215811  215812  ...  I wasn't really sure what to expect here. I'm ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a45E34kc4wt",
        "colab_type": "text"
      },
      "source": [
        "## Load CSV of CFPB Complaints and Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Yh4TnEc4cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfpb_df = pd.read_csv('/content/drive/My Drive/cfpb_summaries_4.csv')\n",
        "\n",
        "sum_df = cfpb_df.dropna(subset=['Summary'])\n",
        "\n",
        "# Build test_df\n",
        "test_df = sum_df.sample(10, random_state=15)\n",
        "\n",
        "test_df['Text'] = test_df['Consumer complaint narrative']\n",
        "\n",
        "test_df = test_df[['Text', 'Summary']]\n",
        "\n",
        "# Remove rows that were sampled for test_df\n",
        "to_remove = test_df.index.tolist()\n",
        "\n",
        "sum_df = sum_df.drop(to_remove)\n",
        "\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsY9-ygrGJrK",
        "colab_type": "code",
        "outputId": "4a73a3d7-a788-42a9-8143-5ce53a120853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(f'\\nNumber of cfpb summaries:', sum_df.shape[0], '\\nNumber of amazon summaries:', neg_df.shape[0], '\\n')\n",
        "\n",
        "print(f'Percent cfpb', 100*round(sum_df.shape[0]/(sum_df.shape[0] + neg_df.shape[0]), 3), '%\\n')"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of cfpb summaries: 514 \n",
            "Number of amazon summaries: 19995 \n",
            "\n",
            "Percent cfpb 2.5 %\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYCgWNyBgO07",
        "colab_type": "text"
      },
      "source": [
        "## Build Combined DataFrame w/ 'X' Copies of CFPB Text & Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqx2mKn0dnj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_df['Text'] = sum_df['Consumer complaint narrative']\n",
        "\n",
        "tmp_df = sum_df[['Text', 'Summary']]\n",
        "\n",
        "tmp_df_2 = neg_df[['Text', 'Summary']]\n",
        "\n",
        "comb_df = tmp_df.append(tmp_df_2)\n",
        "\n",
        "comb_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  comb_df = tmp_df.append(comb_df).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gum3bY5XflTB",
        "colab_type": "code",
        "outputId": "fe8f07cb-6a77-4b0d-cdb9-7f24e691e813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "comb_df.shape"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23079, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7oGRSoSjXVH",
        "colab_type": "text"
      },
      "source": [
        "## Clean Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwuU9vV7eGOo",
        "colab_type": "code",
        "outputId": "67528687-846e-4ec8-9a18-fafcdb47055b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', str(text)) for text in comb_df['Text']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\" Stop Words Import \"\"\"\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "\"\"\" Loops \"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "  \n",
        "  nar_words = [word for word in nar_words if not word in stops]\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "texts = new_words"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkR7UnJqjVzl",
        "colab_type": "text"
      },
      "source": [
        "## Clean Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awjnrhu5dqrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', str(text)) for text in comb_df['Summary']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\" Loops \"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "summaries = new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyiKMJ0dLBxo",
        "colab_type": "text"
      },
      "source": [
        "## Clean Test Text and Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsZUK18lLAsJ",
        "colab_type": "code",
        "outputId": "334ed3fc-af58-4a5e-9e07-5e0a265fd649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Texts\n",
        "\n",
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', str(text)) for text in test_df['Text']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\" Stop Words Import \"\"\"\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "\"\"\" Loops \"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "  \n",
        "  nar_words = [word for word in nar_words if not word in stops]\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "test_texts = new_words\n",
        "\n",
        "# Summaries\n",
        "\n",
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', text) for text in test_df['Summary']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "test_summaries = new_words"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzvU2BwNC8t7",
        "colab_type": "text"
      },
      "source": [
        "## Build Clean Df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuljPAY7j4NX",
        "colab_type": "code",
        "outputId": "60fa02cc-7caf-47fa-8e1a-829eba229850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "comb_df['Cleaned_text'], comb_df['Cleaned_summary'] = texts, summaries\n",
        "\n",
        "clean_df = comb_df[['Cleaned_text', 'Cleaned_summary']]\n",
        "\n",
        "target_texts = []\n",
        "\n",
        "for target_text in clean_df['Cleaned_summary']:\n",
        "\n",
        "  target_text = '_START_ ' + str(target_text) + ' _END_'\n",
        "\n",
        "  target_texts.append(target_text)\n",
        "\n",
        "clean_df['Summary'] = target_texts\n",
        "\n",
        "# test_df\n",
        "\n",
        "test_df['Cleaned_text'], test_df['Cleaned_summary'] = test_texts, test_summaries"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAxO_Cl9DBO7",
        "colab_type": "text"
      },
      "source": [
        "## Train/Val Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOxrP-Ayqw6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text = 100\n",
        "\n",
        "max_len_summary = 7\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(clean_df['Cleaned_text'], clean_df['Summary'], test_size=0.15, random_state=0, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDiDH0qkcVKA",
        "colab_type": "text"
      },
      "source": [
        "## AttentionLayer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI495me0cWpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVKhl6720zgN",
        "colab_type": "text"
      },
      "source": [
        "## (Optional) Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZqzemWPGgtT",
        "colab_type": "code",
        "outputId": "2bdc1276-ea34-4c1b-8e27-75da17aba4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import pickle\n",
        "\n",
        "# model\n",
        "\n",
        "drive_path = '/content/drive/'\n",
        "\n",
        "file_path = 'My Drive/saved_keras_rnns/'\n",
        "\n",
        "name = 'enc_dec_main_u5.h5'\n",
        "\n",
        "model = keras.models.load_model(drive_path + file_path + name, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "# tokenizer\n",
        "\n",
        "name = 'tok_enc_dec_main_u5.pkl'\n",
        "\n",
        "(x_tokenizer, y_tokenizer) = pickle.load(open(drive_path + file_path + name, 'rb'))\n",
        "\n",
        "# build pre-trained model\n",
        "\n",
        "config = model.get_config()\n",
        "\n",
        "weights = model.get_weights()\n",
        "\n",
        "model = tf.keras.Model.from_config(config, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "\n",
        "model.set_weights(weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pBLrbUsDmSP",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF5ClyTiSRnj",
        "colab_type": "text"
      },
      "source": [
        "### Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyYXO_bYrUu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "507116ba-4201-4176-b0a9-3455bdec4168"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# x_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# x_tokenizer.fit_on_texts(list(X_train))\n",
        "\n",
        "# convert text sequences into integer sequences\n",
        "X_train = x_tokenizer.texts_to_sequences(X_train)\n",
        "X_val = x_tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "# padding zero up to maximum length\n",
        "X_train = pad_sequences(X_train, maxlen=max_len_text, padding='post')\n",
        "X_val = pad_sequences(X_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size = len(x_tokenizer.word_index) + 1\n",
        "\n",
        "x_voc_size"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32279"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ro7HJzQSVcS",
        "colab_type": "text"
      },
      "source": [
        "### Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00CqIsQ-sHOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "29792ef0-4c68-4101-d7cb-c6e60eaea8b0"
      },
      "source": [
        "# y_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "# y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "# convert summary sequences into integer sequences\n",
        "y_train = y_tokenizer.texts_to_sequences(y_train)\n",
        "y_val = y_tokenizer.texts_to_sequences(y_val)\n",
        "\n",
        "# padding zero upto maximum length\n",
        "y_train = pad_sequences(y_train, maxlen=max_len_summary, padding='post')\n",
        "y_val = pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size = len(y_tokenizer.word_index) + 1\n",
        "\n",
        "y_voc_size"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiVKalywDoau",
        "colab_type": "text"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLZz6kGCzOva",
        "colab_type": "code",
        "outputId": "53c1f2ca-6e54-4340-b560-500d85028cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "n_neurons = 256\n",
        "\n",
        "embedding_dim = 512\n",
        "\n",
        "dropout_rate = 0\n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = tf.keras.layers.Input(shape=[max_len_text,])\n",
        "enc_emb_layer = tf.keras.layers.Embedding(x_voc_size, embedding_dim, trainable=True)\n",
        "enc_emb = enc_emb_layer(encoder_inputs)\n",
        "\n",
        "# LSTM 1 \n",
        "encoder_lstm_1 = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                      dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
        "encoder_output_1, state_h1, state_c1 = encoder_lstm_1(enc_emb)\n",
        "\n",
        "# LSTM 2 \n",
        "encoder_lstm_2 = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                      dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
        "encoder_output_2, state_h2, state_c2 = encoder_lstm_2(encoder_output_1)\n",
        "\n",
        "# LSTM 3 \n",
        "encoder_lstm_3 = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                      dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm_3(encoder_output_2)\n",
        "\n",
        "# Set up the decoder\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[None,])\n",
        "dec_emb_layer = tf.keras.layers.Embedding(y_voc_size, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# LSTM using encoder_states as initial state\n",
        "decoder_lstm = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                    dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
        "decoder_output_1, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_output_1])\n",
        "decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_output_1, attn_out]) # Concat outputs\n",
        "\n",
        "# Dense layer 1\n",
        "decoder_concat_input = tf.keras.layers.Dropout(0.5)(decoder_concat_input)\n",
        "decoder_dense_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1024, activation='sigmoid'))\n",
        "decoder_output_2 = decoder_dense_1(decoder_concat_input)\n",
        "\n",
        "# Dense output\n",
        "decoder_dense = tf.keras.layers.Dense(y_voc_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_output_2)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_26\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_47 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_28 (Embedding)        (None, 100, 512)     16526848    input_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_56 (LSTM)                  [(None, 100, 256), ( 787456      embedding_28[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_48 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_57 (LSTM)                  [(None, 100, 256), ( 525312      lstm_56[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_29 (Embedding)        (None, None, 512)    3639296     input_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_58 (LSTM)                  [(None, 100, 256), ( 525312      lstm_57[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_59 (LSTM)                  [(None, None, 256),  787456      embedding_29[0][0]               \n",
            "                                                                 lstm_58[0][1]                    \n",
            "                                                                 lstm_58[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_58[0][0]                    \n",
            "                                                                 lstm_59[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 512)    0           lstm_59[0][0]                    \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, None, 512)    0           concat_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_14 (TimeDistri (None, None, 1024)   525312      dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, None, 7108)   7285700     time_distributed_14[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 30,734,020\n",
            "Trainable params: 30,734,020\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkBYORJ9Dqfj",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBAh4GOL4W9v",
        "colab_type": "text"
      },
      "source": [
        "### Build Target Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mFPrLc24Txo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_post = y_train[:,:-1]\n",
        "\n",
        "y_train_post_2 = y_train.reshape(y_train.shape[0], y_train.shape[1], -1)[:,1:]\n",
        "\n",
        "y_val_post = y_val[:,:-1]\n",
        "\n",
        "y_val_post_2 = y_val.reshape(y_val.shape[0], y_val.shape[1], -1)[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaxgrG5A4s79",
        "colab_type": "text"
      },
      "source": [
        "### Establish Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-glAlJS4uXR",
        "colab_type": "code",
        "outputId": "d14367f8-5d1d-4326-99a3-861edc38fa33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Early Stopping\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Checkpointing Model Weights\n",
        "\n",
        "import os\n",
        "\n",
        "checkpoint_path = 'checkpoints/cp-{epoch:03d}.ckpt'\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1,\n",
        "                                                   save_weights_only=True, period=1)\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "latest_checkpoint"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'checkpoints/cp-005.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr6977YU4as8",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-vCfY_2UFKM",
        "colab_type": "code",
        "outputId": "f43300cd-604e-4b4c-ac8b-3987ed4adca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.load_weights(latest_checkpoint)\n",
        "\n",
        "history = model.fit([X_train, y_train_post], y_train_post_2,\n",
        "                    validation_data=([X_val, y_val_post], y_val_post_2),\n",
        "                    batch_size=batch_size, epochs=epochs, callbacks=[early_stop, checkpoint_cb])"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "77/77 [==============================] - ETA: 0s - loss: 2.6716\n",
            "Epoch 00001: saving model to checkpoints/cp-001.ckpt\n",
            "77/77 [==============================] - 18s 230ms/step - loss: 2.6716 - val_loss: 2.5530\n",
            "Epoch 2/5\n",
            "77/77 [==============================] - ETA: 0s - loss: 2.4766\n",
            "Epoch 00002: saving model to checkpoints/cp-002.ckpt\n",
            "77/77 [==============================] - 17s 217ms/step - loss: 2.4766 - val_loss: 2.5442\n",
            "Epoch 3/5\n",
            "77/77 [==============================] - ETA: 0s - loss: 2.3562\n",
            "Epoch 00003: saving model to checkpoints/cp-003.ckpt\n",
            "77/77 [==============================] - 16s 210ms/step - loss: 2.3562 - val_loss: 2.5544\n",
            "Epoch 4/5\n",
            "77/77 [==============================] - ETA: 0s - loss: 2.2649\n",
            "Epoch 00004: saving model to checkpoints/cp-004.ckpt\n",
            "77/77 [==============================] - 16s 210ms/step - loss: 2.2649 - val_loss: 2.5742\n",
            "Epoch 5/5\n",
            "77/77 [==============================] - ETA: 0s - loss: 2.1831\n",
            "Epoch 00005: saving model to checkpoints/cp-005.ckpt\n",
            "77/77 [==============================] - 16s 212ms/step - loss: 2.1831 - val_loss: 2.5882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWZ67pRj_QTu",
        "colab_type": "text"
      },
      "source": [
        "## Save Model and Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN7Q7qLsYdmH",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv0TSP95_Pu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_path = '/content/drive/'\n",
        "\n",
        "file_path = 'My Drive/saved_keras_rnns/'\n",
        "\n",
        "name = 'enc_dec_main_u5.h5'\n",
        "\n",
        "model.save(drive_path + file_path + name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX_6b40aYehp",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQzU7kg9Ygh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "name = 'tok_enc_dec_main_u5.pkl'\n",
        "\n",
        "pickle.dump((x_tokenizer, y_tokenizer), open(drive_path + file_path + name, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbIPSlN2_ds3",
        "colab_type": "text"
      },
      "source": [
        "## Load Model and Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BboVrWqnY_9f",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beNHzdt6_e27",
        "colab_type": "code",
        "outputId": "ad58380c-65ee-46e2-8f48-21d079c6506e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "drive_path = '/content/drive/'\n",
        "\n",
        "file_path = 'My Drive/saved_keras_rnns/'\n",
        "\n",
        "name = 'enc_dec_main.h5'\n",
        "\n",
        "model = keras.models.load_model(drive_path + file_path + name, custom_objects={'AttentionLayer': AttentionLayer})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpCTFw2NZA7l",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0M9ayk6ZCak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'tok_enc_dec_main.pkl'\n",
        "\n",
        "tokenizers_tuple = pickle.load(open(drive_path + file_path + name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYV4ggDc7UNn",
        "colab_type": "text"
      },
      "source": [
        "## Get Word Indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOGI8Pgc7Svp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_source_word_index = x_tokenizer.index_word\n",
        "\n",
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "\n",
        "target_word_index = y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4gGMARU7VJg",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fzzom8vnevs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = tf.keras.Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = tf.keras.layers.Input(shape=(n_neurons,))\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=(n_neurons,))\n",
        "decoder_hidden_state_input = tf.keras.layers.Input(shape=(max_len_text, n_neurons))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb_2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs_2, state_h2, state_c2 = decoder_lstm(dec_emb_2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# Attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs_2])\n",
        "decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs_2, attn_out_inf])\n",
        "\n",
        "# Dense layer\n",
        "decoder_outputs_3 = decoder_dense_1(decoder_inf_concat)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs_4 = decoder_dense(decoder_outputs_3)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = tf.keras.Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "                               [decoder_outputs_4] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LexnhUY-CwLc",
        "colab_type": "text"
      },
      "source": [
        "## Decode Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tvj-s3H_XHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if sampled_token != 'end':\n",
        "\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end') or (len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                \n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa_nBkSd_XEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "\n",
        "    new_string = ''\n",
        "\n",
        "    for i in input_seq:\n",
        "\n",
        "      if ((i != 0 and i != target_word_index['start']) and i != target_word_index['end']):\n",
        "\n",
        "        new_string = new_string + reverse_target_word_index[i] + ' '\n",
        "\n",
        "    return new_string\n",
        "\n",
        "def seq2text(input_seq):\n",
        "\n",
        "    new_string = ''\n",
        "\n",
        "    for i in input_seq:\n",
        "\n",
        "      if i != 0:\n",
        "\n",
        "        new_string = new_string + reverse_source_word_index[i] + ' '\n",
        "        \n",
        "    return new_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwdYz5S-CzuC",
        "colab_type": "text"
      },
      "source": [
        "## Show Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ0Gcp4zdssF",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize Test Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5_YaFcSdcTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_text = x_tokenizer.texts_to_sequences(test_df['Cleaned_text'])\n",
        "\n",
        "test_text = pad_sequences(test_text, maxlen=max_len_text, padding='post')\n",
        "\n",
        "test_sum = y_tokenizer.texts_to_sequences(test_df['Cleaned_summary'])\n",
        "\n",
        "test_sum = pad_sequences(test_sum, maxlen=max_len_summary, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYEyP8GZecj1",
        "colab_type": "text"
      },
      "source": [
        "### Prediction Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxjlP0Fj_VuZ",
        "colab_type": "code",
        "outputId": "3d19f605-c1d6-4ce5-ab77-2552a75a21d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "for i in range(len(test_text)):\n",
        "\n",
        "  print('Review:', seq2text(test_text[i]))\n",
        "\n",
        "  print('Original summary:', seq2summary(test_sum[i]))\n",
        "\n",
        "  print('Predicted summary:', decode_sequence(test_text[i].reshape(1, max_len_text)))\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: i called multiple occasions find intrest the worker told find website i tried look but i cannot also i stopped attending prism misleading programs when i started impression i working towards xxxx degree fact certificate i constantly try get intouch someone help i xxxx balance payment credit keeps going interest please help \n",
            "Original summary: misleading programs student loan help \n",
            "Predicted summary:  misleading marketing ad\n",
            "\n",
            "\n",
            "Review: my mother died xxxxxxxx i inherited xxxx acres family owned along mortgage whitch suspected fradulant loan property worth neer amount money i contacted b of a told thought fradulant fha loan i didnt hear anything fraud department b of a two years got forcloser notice xxxx xxxx collection agency b of after contacting stated going sell property i imeditaly pay amount loan full i conacted congressmens office put contact hud since fha loan this found b of a paid full xxxxxxxx since mortage insurance loan so b of a paid xxxxxxxx still wanting pay loan agin continue try sell property \n",
            "Original summary: fraudulent loan \n",
            "Predicted summary:  mortgage denied\n",
            "\n",
            "\n",
            "Review: it takes month post payments made excessive due continue charge interest i made payments online i n't pay penalty taking long i also n't agree interest charged the interest less month due overall loan status going n't when i making payments mail navient would post extra money i paid lower interest loans well this automatically go towards higher interest loans \n",
            "Original summary: do not agree with interest charged \n",
            "Predicted summary:  mortgage modification\n",
            "\n",
            "\n",
            "Review: i feel personal informantion taken used get car loans credit numerous lenders advised submit form take actions fraudulent accounts open name without authorization i hope bring issue \n",
            "Original summary: faudulent accounts \n",
            "Predicted summary:  frequent calls\n",
            "\n",
            "\n",
            "Review: included agreement instead copies xxxx affidavit note lost included transferred ocwen part servicing transfer multiple associates established conclusion also ocwen produces pooling agreement xxxx xxxx xxxx xxxx xxxx bank neither one part coop conversion files furthermore ocwen first refers xxxx xxxx property management investor investors far i informed do not get original loan documents loan owner gets banks required keep custody per document attached a record events recorded ocwen collateral file reviewed investors returned xxxx xxxxxxxx custodian why ocwen state n't collateral documents issuing affidavit loss documents originally stated original documents never ocwen why return collateral files custodian claim lost \n",
            "Original summary: loan acquired by investors \n",
            "Predicted summary:  loan information delayed by navient\n",
            "\n",
            "\n",
            "Review: i trying get deed since xxxx they keep sending paperwork fill nothing gets done every weeks send letter telling i new account rep process starts i xxxx different people tell sending deed form sign property back paperwork never arrived new rep n't see notes people i talked the loan forgiven bankruptcy giving run around constantly harassing \n",
            "Original summary: trying to get a \n",
            "Predicted summary:  pressured in short sale\n",
            "\n",
            "\n",
            "Review: on sunday xxxx fraudulent charge appeared bank account debit card purchase amount charge appeared xxxx xxxx xxxx xxxx xxxx this charge charge back initiated someone sold electronics months ago clearly fraud its understanding capital one zero percent fraud liability debit cards however i attempted contact issue twice seemed case could help i needed money desperately buy prescription medicine this fraudulent charge stolen bank account i need money back soon possible \n",
            "Original summary: fraudulent charge on debit card \n",
            "Predicted summary:  account in collection\n",
            "\n",
            "\n",
            "Review: back once get money back withdrawal but going i still making payments lowe 's credit card bill like always i notice payments returned late fees interest charges placed onto credit card bills come find xxxx shut transaction lowe 's xxxx without knowing telling done i found self upsetting unfortunately mistakes credit rating suffered immensely i taking court xxxx xxxx paid debt i thought i find i still lowe 's credit card balance charged i looking help getting resolved credit rating improved i'm also xxxx afford pay debt time if lowe 's xxxx xxxx xxxx i would dilemma thank xxxx xxxx \n",
            "Original summary: horrible experience \n",
            "Predicted summary:  denial of loan modification\n",
            "\n",
            "\n",
            "Review: i fully xxxx receiving social security xxxx since xxxx my loan gone away even though supposed stated promissory note i still paying dealing different company xxxx i 've submited evidence xxxx avail thank please help xxxx \n",
            "Original summary: loan payment \n",
            "Predicted summary:  credit card charges\n",
            "\n",
            "\n",
            "Review: collecting agents keep calling aunt instead personal phone number keep talking debt i n't know got phone number worst part xxxx old baby keep calling night asking payment they said send letters n't \n",
            "Original summary: collection agents calling my aunt \n",
            "Predicted summary:  collectors contacting third parties\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnfFKR5p_VrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}