{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "enc_dec_summarizer",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "giT-5ASe_C8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E32KxzGEkz-",
        "colab_type": "code",
        "outputId": "7d01ccf5-febb-46a5-8d2e-93ec001f6523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgLkgP6__HIq",
        "colab_type": "code",
        "outputId": "ab0136c2-4c68-4001-ac32-0a83984d2998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlITgXYtdcfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_df = pd.read_csv('/content/drive/My Drive/Amazon_Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s3bTxQWdcbt",
        "colab_type": "code",
        "outputId": "c04b4123-3828-492f-df97-872b76ad4abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "reviews_df['Score'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    363122\n",
              "4     80655\n",
              "1     52268\n",
              "3     42640\n",
              "2     29769\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRxNV7EudcXr",
        "colab_type": "code",
        "outputId": "e6799bac-17a9-44c4-c909-21246a0051e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "neg_df = reviews_df[reviews_df['Score'] <= 4]\n",
        "\n",
        "neg_df = neg_df.dropna(subset=['Summary'])\n",
        "\n",
        "neg_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>ADT0SRK1MGOEU</td>\n",
              "      <td>Twoapennything</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1342051200</td>\n",
              "      <td>Nice Taffy</td>\n",
              "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>B0009XLVG0</td>\n",
              "      <td>A327PCT23YH90</td>\n",
              "      <td>LT</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1339545600</td>\n",
              "      <td>My Cats Are Not Fans of the New Food</td>\n",
              "      <td>My cats have been happily eating Felidae Plati...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Id  ...                                               Text\n",
              "1    2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2    3  ...  This is a confection that has been around a fe...\n",
              "3    4  ...  If you are looking for the secret ingredient i...\n",
              "5    6  ...  I got a wild hair for taffy and ordered this f...\n",
              "12  13  ...  My cats have been happily eating Felidae Plati...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a45E34kc4wt",
        "colab_type": "text"
      },
      "source": [
        "## Load CSV of CFPB Complaints and Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Yh4TnEc4cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfpb_df = pd.read_csv('/content/drive/My Drive/cfpb_summaries.csv')\n",
        "\n",
        "sum_df = cfpb_df.dropna(subset=['Summary'])\n",
        "\n",
        "# Build test_df\n",
        "test_df = sum_df.sample(10, random_state=42)\n",
        "\n",
        "test_df['Text'] = test_df['Consumer complaint narrative']\n",
        "\n",
        "test_df = test_df[['Text', 'Summary']]\n",
        "\n",
        "# Remove rows that were sampled for test_df\n",
        "to_remove = test_df.index.tolist()\n",
        "\n",
        "sum_df = sum_df.drop(to_remove)\n",
        "\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYCgWNyBgO07",
        "colab_type": "text"
      },
      "source": [
        "## Build Combined DataFrame w/ 'X' Copies of CFPB Text & Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqx2mKn0dnj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum_df['Text'] = sum_df['Consumer complaint narrative']\n",
        "\n",
        "tmp_df = sum_df[['Text', 'Summary']]\n",
        "\n",
        "tmp_df_2 = neg_df[['Text', 'Summary']]\n",
        "\n",
        "comb_df = tmp_df.append(tmp_df_2)\n",
        "\n",
        "comb_df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "for i in range(20):\n",
        "\n",
        "  comb_df = tmp_df.append(comb_df).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gum3bY5XflTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2eb62d9a-ceb0-4641-c265-fee00d12b455"
      },
      "source": [
        "comb_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(208896, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7oGRSoSjXVH",
        "colab_type": "text"
      },
      "source": [
        "## Clean Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwuU9vV7eGOo",
        "colab_type": "code",
        "outputId": "e8ed7529-6550-4f43-d767-19b7d0382574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', text) for text in comb_df['Text']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\" Stop Words Import \"\"\"\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "\"\"\" Loops \"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "  \n",
        "  nar_words = [word for word in nar_words if not word in stops]\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "texts = new_words"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkR7UnJqjVzl",
        "colab_type": "text"
      },
      "source": [
        "## Clean Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awjnrhu5dqrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', text) for text in comb_df['Summary']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\" Loops \"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "summaries = new_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyiKMJ0dLBxo",
        "colab_type": "text"
      },
      "source": [
        "## Clean Test Text and Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsZUK18lLAsJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e0a9f3db-001e-41e0-9a8a-41ebadc728de"
      },
      "source": [
        "# Texts\n",
        "\n",
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', text) for text in test_df['Text']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\" Stop Words Import \"\"\"\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "\"\"\" Loops \"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "  \n",
        "  nar_words = [word for word in nar_words if not word in stops]\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "test_texts = new_words\n",
        "\n",
        "# Summaries\n",
        "\n",
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', text) for text in test_df['Summary']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "  new_words.append(' '.join(nar_words))\n",
        "\n",
        "test_summaries = new_words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzvU2BwNC8t7",
        "colab_type": "text"
      },
      "source": [
        "## Build Clean Df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuljPAY7j4NX",
        "colab_type": "code",
        "outputId": "e2484dcf-4d9b-495c-8256-61c90409f2a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "comb_df['Cleaned_text'], comb_df['Cleaned_summary'] = texts, summaries\n",
        "\n",
        "clean_df = comb_df[['Cleaned_text', 'Cleaned_summary']]\n",
        "\n",
        "target_texts = []\n",
        "\n",
        "for target_text in clean_df['Cleaned_summary']:\n",
        "\n",
        "  target_text = '_START_ ' + str(target_text) + ' _END_'\n",
        "\n",
        "  target_texts.append(target_text)\n",
        "\n",
        "clean_df['Summary'] = target_texts\n",
        "\n",
        "# test_df:\n",
        "test_df['Cleaned_text'], test_df['Cleaned_summary'] = test_texts, test_summaries"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAxO_Cl9DBO7",
        "colab_type": "text"
      },
      "source": [
        "## Train/Val Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOxrP-Ayqw6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_text = 100\n",
        "\n",
        "max_len_summary = 10\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(clean_df['Cleaned_text'], clean_df['Summary'], test_size=0.15, random_state=0, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM1lX9UgCaDk",
        "colab_type": "code",
        "outputId": "02d992cc-f0c5-4fb3-d7f6-a92663b1422f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "clean_df['Summary'].sample(1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80871    _START_ Total rip off _END_\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pBLrbUsDmSP",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF5ClyTiSRnj",
        "colab_type": "text"
      },
      "source": [
        "### Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyYXO_bYrUu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00b079f8-a17f-4e7f-a102-3632c2dc2e99"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "x_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "x_tokenizer.fit_on_texts(list(X_train))\n",
        "\n",
        "# convert text sequences into integer sequences\n",
        "X_train = x_tokenizer.texts_to_sequences(X_train)\n",
        "X_val = x_tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "# padding zero up to maximum length\n",
        "X_train = pad_sequences(X_train, maxlen=max_len_text, padding='post')\n",
        "X_val = pad_sequences(X_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size = len(x_tokenizer.word_index) + 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ro7HJzQSVcS",
        "colab_type": "text"
      },
      "source": [
        "### Summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00CqIsQ-sHOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "\n",
        "y_tokenizer.fit_on_texts(list(y_train))\n",
        "\n",
        "# convert summary sequences into integer sequences\n",
        "y_train = y_tokenizer.texts_to_sequences(y_train)\n",
        "y_val = y_tokenizer.texts_to_sequences(y_val)\n",
        "\n",
        "# padding zero upto maximum length\n",
        "y_train = pad_sequences(y_train, maxlen=max_len_summary, padding='post')\n",
        "y_val = pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size = len(y_tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDiDH0qkcVKA",
        "colab_type": "text"
      },
      "source": [
        "## AttentionLayer Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI495me0cWpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiVKalywDoau",
        "colab_type": "text"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLZz6kGCzOva",
        "colab_type": "code",
        "outputId": "9527d128-eedc-477a-b14e-80cd385f398e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "n_neurons = 256\n",
        "\n",
        "embedding_dim = 512\n",
        "\n",
        "dropout_rate = 0.25\n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = tf.keras.layers.Input(shape=[max_len_text,])\n",
        "enc_emb_layer = tf.keras.layers.Embedding(x_voc_size, embedding_dim, trainable=True)\n",
        "enc_emb = enc_emb_layer(encoder_inputs)\n",
        "\n",
        "# LSTM 1 \n",
        "encoder_lstm_1 = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                      dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
        "encoder_output_1, state_h1, state_c1 = encoder_lstm_1(enc_emb)\n",
        "\n",
        "# LSTM 2 \n",
        "encoder_lstm_2 = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                      dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
        "encoder_output_2, state_h2, state_c2 = encoder_lstm_2(encoder_output_1)\n",
        "\n",
        "# LSTM 3 \n",
        "encoder_lstm_3 = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                      dropout=dropout_rate, recurrent_dropout=dropout_rate)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm_3(encoder_output_2)\n",
        "\n",
        "# Set up the decoder.\n",
        "decoder_inputs = tf.keras.layers.Input(shape=[None,])\n",
        "dec_emb_layer = tf.keras.layers.Embedding(y_voc_size, embedding_dim, trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# LSTM using encoder_states as initial state\n",
        "decoder_lstm = tf.keras.layers.LSTM(n_neurons, return_sequences=True, return_state=True,\n",
        "                                    dropout=0.25, recurrent_dropout=0.25)\n",
        "decoder_output_1, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c])\n",
        "\n",
        "# Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer')\n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_output_1])\n",
        "\n",
        "# Concat attention output and decoder LSTM output\n",
        "decoder_concat_input = tf.keras.layers.Concatenate(axis=-1, name='concat_layer')([decoder_output_1, attn_out])\n",
        "\n",
        "# Dense layer 1\n",
        "decoder_concat_input = tf.keras.layers.Dropout(0.5)(decoder_concat_input)\n",
        "decoder_dense_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1024, activation='sigmoid'))\n",
        "decoder_output_2 = decoder_dense_1(decoder_concat_input)\n",
        "\n",
        "# Dense output\n",
        "decoder_dense = tf.keras.layers.Dense(y_voc_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_output_2)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 100, 512)     50712576    input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, 100, 256), ( 787456      embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, 100, 256), ( 525312      lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 512)    10909184    input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, 100, 256), ( 525312      lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   [(None, None, 256),  787456      embedding_3[0][0]                \n",
            "                                                                 lstm_6[0][1]                     \n",
            "                                                                 lstm_6[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_6[0][0]                     \n",
            "                                                                 lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 512)    0           lstm_7[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 512)    0           concat_layer[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, None, 1024)   525312      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, None, 21307)  21839675    time_distributed_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 86,743,611\n",
            "Trainable params: 86,743,611\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkBYORJ9Dqfj",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBAh4GOL4W9v",
        "colab_type": "text"
      },
      "source": [
        "### Build Target Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mFPrLc24Txo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_post = y_train[:,:-1]\n",
        "\n",
        "y_train_post_2 = y_train.reshape(y_train.shape[0], y_train.shape[1], -1)[:,1:]\n",
        "\n",
        "y_val_post = y_val[:,:-1]\n",
        "\n",
        "y_val_post_2 = y_val.reshape(y_val.shape[0], y_val.shape[1], -1)[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaxgrG5A4s79",
        "colab_type": "text"
      },
      "source": [
        "### Establish Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-glAlJS4uXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44517443-f8cc-412e-d50b-328dadeeb676"
      },
      "source": [
        "# Early Stopping\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
        "\n",
        "# Checkpointing Model Weights\n",
        "\n",
        "import os\n",
        "\n",
        "checkpoint_path = 'checkpoints/cp-{epoch:03d}.ckpt'\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1,\n",
        "                                                   save_weights_only=True, period=1)\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "latest_checkpoint"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'checkpoints/cp-010.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr6977YU4as8",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-vCfY_2UFKM",
        "colab_type": "code",
        "outputId": "c0844034-9c28-4f60-eea4-ffee1ee3919f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.load_weights(latest_checkpoint)\n",
        "\n",
        "history = model.fit([X_train, y_train_post], y_train_post_2,\n",
        "                    validation_data=([X_val, y_val_post], y_val_post_2),\n",
        "                    batch_size=batch_size, epochs=epochs, callbacks=[early_stop, checkpoint_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 20/694 [..............................] - ETA: 14:27 - loss: 1.6381"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWZ67pRj_QTu",
        "colab_type": "text"
      },
      "source": [
        "## Save Model and Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN7Q7qLsYdmH",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv0TSP95_Pu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_path = '/content/drive/'\n",
        "\n",
        "file_path = 'My Drive/saved_keras_rnns/'\n",
        "\n",
        "name = 'enc_dec_main_u3.h5'\n",
        "\n",
        "model.save(drive_path + file_path + name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX_6b40aYehp",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQzU7kg9Ygh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "name = 'tok_enc_dec_main_u3.pkl'\n",
        "\n",
        "pickle.dump((x_tokenizer, y_tokenizer), open(drive_path + file_path + name, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbIPSlN2_ds3",
        "colab_type": "text"
      },
      "source": [
        "## Load Model and Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BboVrWqnY_9f",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beNHzdt6_e27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "300b8cae-4fa2-4485-b3db-f70f7b1165d8"
      },
      "source": [
        "drive_path = '/content/drive/'\n",
        "\n",
        "file_path = 'My Drive/saved_keras_rnns/'\n",
        "\n",
        "name = 'enc_dec_main.h5'\n",
        "\n",
        "model = keras.models.load_model(drive_path + file_path + name, custom_objects={'AttentionLayer': AttentionLayer})"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpCTFw2NZA7l",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0M9ayk6ZCak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'tok_enc_dec_main.pkl'\n",
        "\n",
        "tokenizers_tuple = pickle.load(open(drive_path + file_path + name, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYV4ggDc7UNn",
        "colab_type": "text"
      },
      "source": [
        "## Get Word Indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOGI8Pgc7Svp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_source_word_index = x_tokenizer.index_word\n",
        "\n",
        "reverse_target_word_index = y_tokenizer.index_word\n",
        "\n",
        "target_word_index = y_tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4gGMARU7VJg",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fzzom8vnevs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = tf.keras.Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = tf.keras.layers.Input(shape=(n_neurons,))\n",
        "decoder_state_input_c = tf.keras.layers.Input(shape=(n_neurons,))\n",
        "decoder_hidden_state_input = tf.keras.layers.Input(shape=(max_len_text, n_neurons))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb_2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs_2, state_h2, state_c2 = decoder_lstm(dec_emb_2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# Attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs_2])\n",
        "decoder_inf_concat = tf.keras.layers.Concatenate(axis=-1, name='concat')([decoder_outputs_2, attn_out_inf])\n",
        "\n",
        "# Dense layer\n",
        "decoder_outputs_3 = decoder_dense_1(decoder_inf_concat)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs_4 = decoder_dense(decoder_outputs_3)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = tf.keras.Model([decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n",
        "                               [decoder_outputs_4] + [state_h2, state_c2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LexnhUY-CwLc",
        "colab_type": "text"
      },
      "source": [
        "## Decode Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tvj-s3H_XHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if sampled_token != 'end':\n",
        "\n",
        "            decoded_sentence += ' ' + sampled_token\n",
        "\n",
        "            # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end') or (len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "                \n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa_nBkSd_XEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "\n",
        "    new_string = ''\n",
        "\n",
        "    for i in input_seq:\n",
        "\n",
        "      if ((i != 0 and i != target_word_index['start']) and i != target_word_index['end']):\n",
        "\n",
        "        new_string = new_string + reverse_target_word_index[i] + ' '\n",
        "\n",
        "    return new_string\n",
        "\n",
        "def seq2text(input_seq):\n",
        "\n",
        "    new_string = ''\n",
        "\n",
        "    for i in input_seq:\n",
        "\n",
        "      if i != 0:\n",
        "\n",
        "        new_string = new_string + reverse_source_word_index[i] + ' '\n",
        "        \n",
        "    return new_string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwdYz5S-CzuC",
        "colab_type": "text"
      },
      "source": [
        "## Show Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ0Gcp4zdssF",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize Test Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5_YaFcSdcTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_text = x_tokenizer.texts_to_sequences(test_df['Cleaned_text'])\n",
        "\n",
        "test_text = pad_sequences(test_text, maxlen=max_len_text, padding='post')\n",
        "\n",
        "test_sum = y_tokenizer.texts_to_sequences(test_df['Cleaned_summary'])\n",
        "\n",
        "test_sum = pad_sequences(test_sum, maxlen=max_len_summary, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYEyP8GZecj1",
        "colab_type": "text"
      },
      "source": [
        "### Prediction Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxjlP0Fj_VuZ",
        "colab_type": "code",
        "outputId": "2ea49e77-98e0-4abf-f186-da0feabb8975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "for i in range(len(test_text)):\n",
        "\n",
        "  print('Review:', seq2text(test_text[i]))\n",
        "\n",
        "  print('Original summary:', seq2summary(test_sum[i]))\n",
        "\n",
        "  print('Predicted summary:', decode_sequence(test_text[i].reshape(1, max_len_text)))\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: have tried close regions bank account week called saturday xxxx told closed i check today xxxx voila 's magically opened i charged another service fee called today told fee posted yesterday xxxx automatically opened account back i ca n't close fee pending this absolutely ridiculous \n",
            "Original summary: bank account opened without \n",
            "Predicted summary:  great coffee but\n",
            "\n",
            "\n",
            "Review: xxxx xxxx xxxx xxxx xxxx va unauthorized credit creditor i recently received copy xxxx xxxx xxxx credit report the credit report showed credit inquiry company i recall authorizing i understand n't allowed put inquiry file unless i authorized please inquiry removed credit files making difficult acquire credit send us written authorization gave access credit files ss xxxx xxxx xxxx xxxx xxxx xxxx \n",
            "Original summary: credit pull not \n",
            "Predicted summary:  disputed late payments\n",
            "\n",
            "\n",
            "Review: multiple cra violations inaccurate information including names addresses phone numbers employment history pretty much entire report \n",
            "Original summary: inaccurate information in entire report \n",
            "Predicted summary:  unacceptable handling of data breach\n",
            "\n",
            "\n",
            "Review: a current report experian reporting xxxx xxxx xxxx paid collection deleted credit file back xxxx xxxx added back file experian the cra provide notice violation section b \n",
            "Original summary: credit reporting paid collection \n",
            "Predicted summary:  reinserted removed item on credit report\n",
            "\n",
            "\n",
            "Review: information credit score xxxx years old got hurt work around xxxxxxxx tried go back work xxxxxxxx could trying go back work credit score let thing work injury makes unreliable n't take care social security pay even near making country take care working men get hurt job worked hard life getting ready retire homeless nothing \n",
            "Original summary: old credit score information \n",
            "Predicted summary:  cell phone calls about debt\n",
            "\n",
            "\n",
            "Review: nj higher education reporting two accounts xxxx credit report correct xxxx shows balance xxxx shows balance they actually confirmed phone i one account i making payments this inaccurate violation fcra \n",
            "Original summary: two accounts incorrectly reported on credit report \n",
            "Predicted summary:  victim of identity theft\n",
            "\n",
            "\n",
            "Review: took payday loan ace cash check xxxx xxxx tx back took another could afford pay back tried set plan told i could longer pay debt went company company sending harassing emails threatening sue garnish paycheck jail time i also get phones calls phone number xxxx calling job xxxx rude threatening i set payment plan i trust people calling call numbers back nobody ever answers please help i need \n",
            "Original summary: payday loan debt sold to debt collection company \n",
            "Predicted summary:  ok for a loyal customer\n",
            "\n",
            "\n",
            "Review: my bank wells fargo bank offers alerting '' service accounts i opt get notified via email text message the message titled overdraft protection advance notice '' that implies i notified advance i opportunity correct balance order avoid overdraft fees however alerts '' sent day charges actually charged accounts this blatantly deceptive result class action law suit \n",
            "Original summary: protection is deceptive \n",
            "Predicted summary:  unethical delay tactics to prevent users from trading\n",
            "\n",
            "\n",
            "Review: reviewing credit report xxxxxxxx inquiries showing credit report i recognize inquiries i actually gave consent pull report xxxx xxxx xxxxxxxx xxxx xxxx xxxx xxxx xxxxxxxx xxxxxxxx \n",
            "Original summary: credit report showing incorrect credit inquiries \n",
            "Predicted summary:  victim of identity theft\n",
            "\n",
            "\n",
            "Review: i loan navient currently lawsuit also school i received loan also law my original started direct soi also requesting verification amount loan matter caused lot stress family get help loans navient make really hard anything life reports leave credit report lawsuit reason i filing complaint charging imposing fees i never agreed loan amount \n",
            "Original summary: requesting verification of loan \n",
            "Predicted summary:  loan payments with no modification\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnfFKR5p_VrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ske2UlbQ_Vo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NCi_qkmdo1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J-nRU_LdozS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kivl0qBdoxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTZ1kxExdouh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGrjuHczQsPK",
        "colab_type": "code",
        "outputId": "8262633c-01cc-4d68-9735-a3bffc337afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "nums = [1, 2]\n",
        "\n",
        "letters = ['a', 'b', 'c']\n",
        "\n",
        "cols = pd.MultiIndex.from_product([nums, letters], names=['Nums', 'Letters'])\n",
        "\n",
        "df = pd.DataFrame(np.random.randint(100, size=(5,6)), columns=cols)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>Nums</th>\n",
              "      <th colspan=\"3\" halign=\"left\">1</th>\n",
              "      <th colspan=\"3\" halign=\"left\">2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Letters</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>34</td>\n",
              "      <td>61</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25</td>\n",
              "      <td>77</td>\n",
              "      <td>39</td>\n",
              "      <td>56</td>\n",
              "      <td>54</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>87</td>\n",
              "      <td>98</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "      <td>30</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>90</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>51</td>\n",
              "      <td>21</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>29</td>\n",
              "      <td>43</td>\n",
              "      <td>74</td>\n",
              "      <td>82</td>\n",
              "      <td>55</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Nums      1           2        \n",
              "Letters   a   b   c   a   b   c\n",
              "0        58  34  61  11   1   2\n",
              "1        25  77  39  56  54  33\n",
              "2        87  98   3  59  30  68\n",
              "3        90  17   7  51  21  96\n",
              "4        29  43  74  82  55  32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "235YRFgxQsJ2",
        "colab_type": "code",
        "outputId": "9c0b2e22-cb73-4dd6-eeee-2ca316d8c415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[58, 34, 61, 11,  1,  2],\n",
              "       [25, 77, 39, 56, 54, 33],\n",
              "       [87, 98,  3, 59, 30, 68],\n",
              "       [90, 17,  7, 51, 21, 96],\n",
              "       [29, 43, 74, 82, 55, 32]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4B1a4wReGJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK-iruJ0_j67",
        "colab_type": "code",
        "outputId": "58a9cc52-c3e4-4c03-f635-bd90b9be0a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "master_df = pd.read_csv('/content/drive/My Drive/Consumer_Complaints.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XV2EEFDKFuo",
        "colab_type": "code",
        "outputId": "87207a46-1890-44b6-a5e2-903821820d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "proc_df = master_df.dropna(subset=['Consumer complaint narrative']).sample(100, random_state=55)\n",
        "\n",
        "pd.set_option('max_colwidth', -1)\n",
        "\n",
        "proc_df['Consumer complaint narrative'].head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "262542     This is in response to my initial complaint XXXX regarding mortgage discrimination by Chase. Despite writing to the executive board, nothing was done other than get some random person to call me and say they received my complaint. Nothing was done and they still refused my loan. No review of their practices of discrimination, no accountability, not even the bare minimum of refunding the charge they made for conducting an appraisal. \\nThe bank lied to the CFPB when they said they were looking into the matter. Loan manager XXXX called me two weeks ago and said they could not honor the loan terms they provided me in writing. They are still demanding 18 months of reserves despite other big banks and credit unions confirming that 6 months was the industry norm for someone with my credit score and financial situation. \\nI have a document from them with loan disclosures they have agreed to but now refuse to provide. Nothing has changed in my financial situation. Why do banks get to behave like XXXX with no accountability?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
              "316136     On XX/XX/XXXX I sent NCB Management Services a Cease and Desist letter that was delivered and signed on XX/XX/XXXX.\\n\\nOn XX/XX/XXXX I sent NCB Management Services a copy of a complaint letter that I sent the Bureau of Financial Protection. The letter was delivered on XX/XX/XXXX.\\n\\nNCB Management Services has not been in compliance and are in violation of the FCRA and FDCPA. Please see enclosed documentation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
              "872043     Chase Bank issued me a XXXX for 2013 in the amount of {$14000.00} for credit card account number XXXX. My Federal Tax Return Form XXXX for 2013 included same amount. Chase Bank has yet to advise the credit reporting repositories ( XXXX, XXXX and XXXX ) that said account should be list as \" {$0.00} BALANCE, PAID IN FULL ''.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
              "469666     XXXX XXXX, 2017, I received an email message that there had been an expenditure on my closed credit card account. When I telephoned the company to report the theft, I was phished for information that included my account password. I refused to divulge it and the operator would not investigate the problem or transfer me to the security people. The credited card issuer is Wells Fargo. I had closed the account last year. Apparently, Wells Fargo is encouraging illegal activities among its staff again.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
              "82573      This is XXXX XXXX XXXX, ad Astra Recovery call to say owe debt was paid XX/XX/2018. FTC should be able to sue their real company is XXXX XXXX and not a ligenamate company that is a collection agencies. I want XXXX XXXX and XXXX XXXX XXXX in order to satisfy my difficulties. \\nXXXX XXXX XXXX, XXXX ( XXXX ) XXXX mobile                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
              "601827     To whom it may concern, On Sunday  XXXX   XXXX  I reported to Chase Bank that my card had been stolen and fraudulent transactions had occurred without my authorization. The transactions that were a result of my card and pin number being compromised are detailed below : ATM DEBIT  XXXX   XXXX   XXXX   XXXX  - {$500.00}  XXXX  POS DEBIT   XXXX   - {$850.00}  XXXX  POS DEBIT  XXXX  - {$850.00}  XXXX   POS DEBIT   XXXX  - {$28.00}  XXXX  ATM  DEBIT    XXXX   - {$42.00}  XXXX   POS DEBIT   XXXX  - {$58.00}  XXXX  The last authorized transaction I made was at an ATM withdrawal for {$100.00} at  XXXX  at  XXXX   XXXX   XXXX   XXXX . That was the last time I saw and used my card, from that point on I was unable to find my card. I woke up and found that my card was missing from my wallet, looked around some, then checked my account to see the balance. Once I saw that unauthorized transactions had occurred I called chase claims immediately.   When I called claims I was incredibly distraught and overwhelmed by my account having been compromised and drained of all funds. I provided information to Chase claims based on what I assumed had happened with the card. My card was lost and somehow the pin number was compromised without my consent or authorization, so I subsequently filed a police report with  XXXX  PD regarding the illegal activity.   Chase Bank denied the fraudulent claim based on the information I provided them the morning of finding out my card had been lost. They believe that I gave consent and authorization for these transactions by giving my pin number to someone and then that person then making every charge thereafter which I disputed the following morning as fraudulent, when in reality, I was with someone at the time of my last ATM withdrawal, but this does not dictate that this person was absolutely the one who somehow retrieved my pin and then made the following transactions as cited above. Chase denied my claim when under the circumstances I should have been protected against this case of fraud because I did not make or authorize any of these transactions, nor did I give away my pin number with consent for someone other than myself to make transactions on my behalf.  <P/>  Chase  claim # :  XXXX  Checking account # :  XXXX   XXXX   PD   Debit Card fraud c ase # :  XXXX   XXXX   PD  Lost Property case # :  XXXX\n",
              "913740     I have continually made overpayments towards my vehicle loan in an effort to reduce the principle amount and, in turn, reduce the amount of interest being paid towards my loan. I contacted FIFSG ( First Investors Financial ) when I noticed all of my overpayments were being split between principle and interest. I contacted FIFSG the first time via telephone and was advised this would be corrected. When my payment was made in XXXX 2015, I reviewed my account and noticed the first request and resolution had not been honored and my overpayment again was split between principle and interest. I sent an email and received a response to allow XXXX hours for my request to be processed and the change to occur. After making my XXXX 2015 payment, I again noticed no action had been taken to correct the payment allocation on the overpayments and my XXXX payment had, again, followed the same pattern. When I contacted FIFSG on XXXX/XXXX/2015, I spoke with a gentleman who identified himself as XXXX XXXX, a Team Lead. I explained my reason for calling, how I contacted the company twice before and no changes had been made. XXXX XXXX then tried to tell me how my interest was being calculated on a per diem basis and why the amount of the per diem interest was being calculated and I have a simple interest loan. I explained to XXXX XXXX my request was to have the overpayments applied to the principle and the interest remediated, I was advised both verbally and in writing this would be done and my account still shows no changes. XXXX XXXX continued to explain to me how interest worked and I advised I was well aware of how Finance worked considering this is my career field. I then advised I was going to file with the CFPB if this did not get changed. XXXX XXXX continued to argue with me and I ended the phone call with the statement of filing with the CFPB to step in and help.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
              "1010699    For 3 years Allied Interstate has been calling for an unknown person to me, XXXX XXXX, and will not stop with the calls no matter how many times they have been told to remove our phone number. Speaking to a supervisor does not help either. I am told they are sorry and will stopand then the calls happen again and again every day, several times a day, morning or night. They are making our lives a living hell even with a answering machine.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
              "495017     All 3 of my credit reports have been exposed and breached and the federal and private loan officerso like XXXX XXXX is reporting inaccurate information on my report showing delinquent when I have not graduate from school just yet. This is causing issues for my lively hood.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
              "539539     Someone has been using my credit information and are applying for credit cards.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
              "Name: Consumer complaint narrative, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2qiHAy_KaZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summaries = [\n",
        "             'Chase refused my loan and charged me for the appraisal.',\n",
        "             'NCB Management Services is not complying with a cease and desist letter.',\n",
        "             'Chase is not reporting to the credit agencies that my account is paid in full.',\n",
        "             'Expenditures on a closed Wells Fargo credit card.',\n",
        "             'Collection agency collecting debt that was paid.',\n",
        "             ''\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSUqa1mmTF4N",
        "colab_type": "text"
      },
      "source": [
        "## Sample and Process Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx6xIRwk_w3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proc_df = master_df.dropna(subset=['Consumer complaint narrative']).sample(100, random_state=55)\n",
        "\n",
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', nar) for nar in proc_df['Consumer complaint narrative']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\"End Contraction Import\"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "  new_words.append(nar_words)\n",
        "\n",
        "words = [word for words in new_words for word in words]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9cKM19tTLJi",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAfI4Onw_3ir",
        "colab_type": "code",
        "outputId": "84f113d6-022f-4c18-a2bf-c4745e06b18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "num_words = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_words, filters='')\n",
        "\n",
        "tokenizer.fit_on_texts(words)\n",
        "\n",
        "encoded = tokenizer.texts_to_sequences(words)\n",
        "\n",
        "max_id = num_words\n",
        "\n",
        "dataset_size = tokenizer.document_count\n",
        "\n",
        "flat_encoded = [enc for encoder in encoded for enc in encoder]\n",
        "\n",
        "print(max_id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5-GJJrXTOdM",
        "colab_type": "text"
      },
      "source": [
        "## Split Train and Val Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZZyo8gh_6Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = dataset_size * 90 // 100\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(flat_encoded[:train_size])\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(flat_encoded[train_size:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YBzSUUkTQQO",
        "colab_type": "text"
      },
      "source": [
        "## Batch and Prepare Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWS2Mzb_8A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "n_steps = 50\n",
        "\n",
        "window_length = n_steps + 1\n",
        "\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "\n",
        "dataset = dataset.map(lambda X_batch, y_batch: (tf.one_hot(X_batch, depth=max_id), y_batch))\n",
        "\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7hNzKoaTT_t",
        "colab_type": "text"
      },
      "source": [
        "## Batch and Prepare Val Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ11iYm8__B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = val_dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "\n",
        "val_dataset = val_dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "val_dataset = val_dataset.shuffle(10000).batch(batch_size)\n",
        "\n",
        "val_dataset = val_dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "\n",
        "val_dataset = val_dataset.map(lambda X_batch, y_batch: (tf.one_hot(X_batch, depth=max_id), y_batch))\n",
        "\n",
        "val_dataset = val_dataset.prefetch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfXB6GSUOWqO",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW1kZCD4zqlM",
        "colab_type": "code",
        "outputId": "1edc218c-87a7-4ba6-bcf3-28bc9303c937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Early Stopping\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopper = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
        "\n",
        "# Checkpoing Model Weights\n",
        "\n",
        "import os\n",
        "\n",
        "checkpoint_path = 'checkpoints/cp-{epoch:04d}.ckpt'\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    period=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHMHrt4zTWze",
        "colab_type": "text"
      },
      "source": [
        "## Identify Last Epoch Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJrFnmyElWXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "latest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mVvv3J4ThZi",
        "colab_type": "text"
      },
      "source": [
        "## Size of Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oESe7TX5ABaF",
        "colab_type": "code",
        "outputId": "551cd95e-9a4e-4bb9-cc8e-8751c559b56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "steps_per_epoch = train_size // batch_size\n",
        "\n",
        "steps_per_epoch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "902P8Fq3TkTZ",
        "colab_type": "text"
      },
      "source": [
        "## Build and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGHvprrVADSD",
        "colab_type": "code",
        "outputId": "3bc546e4-a2e5-49b9-8720-ca012adf0677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "adam = tf.keras.optimizers.Adam()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.GRU(256, return_sequences=True,\n",
        "                                                        dropout=0.5, recurrent_dropout=0.5,\n",
        "                                                        input_shape=[None, max_id]),\n",
        "                                    tf.keras.layers.GRU(256, return_sequences=True,\n",
        "                                                        dropout=0.5, recurrent_dropout=0.5),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(256, activation='sigmoid'),\n",
        "                                    tf.keras.layers.Dense(max_id, activation='softmax')])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# model.load_weights(latest)\n",
        "\n",
        "model.fit(dataset, epochs=5, validation_data=val_dataset, callbacks=[early_stopper, checkpoint_cb])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "      1/Unknown - 2s 2s/step\n",
            "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:842: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r      1/Unknown - 2s 2s/step"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-71d9c66f9fcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# model.load_weights(latest)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_feed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 85\u001b[0;31m         per_replica_function, args=args)\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    762\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 763\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics, standalone)\u001b[0m\n\u001b[1;32m    431\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    313\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    271\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[1;32m    272\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    442\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m           kwargs={\"name\": name})\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1947\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1954\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   1955\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1956\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1957\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    486\u001b[0m           update_ops.extend(\n\u001b[1;32m    487\u001b[0m               distribution.extended.update(\n\u001b[0;32m--> 488\u001b[0;31m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1541\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2174\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   2178\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    468\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    205\u001b[0m           \u001b[0mcoefficients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epsilon'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m           use_locking=self._use_locking)\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mvhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vhat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/gen_training_ops.py\u001b[0m in \u001b[0;36mresource_apply_adam\u001b[0;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m                              \u001b[0mbeta2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m                              \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m                              use_nesterov=use_nesterov, name=name)\n\u001b[0m\u001b[1;32m   1437\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0mResourceApplyAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw_ops.ResourceApplyAdam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_raw_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_apply_adam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    466\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m               \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m               preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         raise RuntimeError(\"Attempting to capture an EagerTensor without \"\n\u001b[1;32m   1281\u001b[0m                            \"building a function.\")\n\u001b[0;32m-> 1282\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcapture\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m       \u001b[0;31m# Large EagerTensors and resources are captured with Placeholder ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_capture_helper\u001b[0;34m(self, tensor, name, shape)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcapture\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m       placeholder = _create_substitute_placeholder(\n\u001b[0;32m--> 650\u001b[0;31m           tensor, name=name, dtype=tensor.dtype, shape=shape)\n\u001b[0m\u001b[1;32m    651\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_capture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_substitute_placeholder\u001b[0;34m(value, name, dtype, shape)\u001b[0m\n\u001b[1;32m   1117\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     placeholder = graph_placeholder(\n\u001b[0;32m-> 1119\u001b[0;31m         dtype=dtype or value.dtype, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   1120\u001b[0m   \u001b[0mcustom_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mplaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m     36\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m     37\u001b[0m       \u001b[0;34m\"Placeholder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m       attrs={\"dtype\": dtype_value, \"shape\": shape}, name=name)\n\u001b[0m\u001b[1;32m     39\u001b[0m   \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3322\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1786\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     \u001b[0;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[0;31m# It might be worth creating a convenient way to re-use the same status.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m     \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_SetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserialized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkbiSXd7kWu8",
        "colab_type": "code",
        "outputId": "069152c5-6d02-49a8-b08c-5cca9562f40f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_30 (GRU)                 (None, None, 256)         7878144   \n",
            "_________________________________________________________________\n",
            "gru_31 (GRU)                 (None, None, 256)         394752    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, None, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, None, 10000)       2570000   \n",
            "=================================================================\n",
            "Total params: 10,908,688\n",
            "Trainable params: 10,908,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha6YqnWwc4Gi",
        "colab_type": "text"
      },
      "source": [
        "## Save the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-aAO0TvdTTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_path = '/content/drive/'\n",
        "\n",
        "file_path = 'My Drive/saved_keras_rnns/'\n",
        "\n",
        "name = 'gru_50_steps_no_emb.h5'\n",
        "\n",
        "model.save(drive_path + file_path + name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TKPz18_A2k7",
        "colab_type": "text"
      },
      "source": [
        "## Save the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpny2hXlA4W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "tokenizer_name = 'tok_gru_50_steps_no_emb.pkl'\n",
        "\n",
        "pickle.dump(tokenizer, open(drive_path + file_path + tokenizer_name, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfRRUk4EywYL",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpsZDDXMePG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'gru_30_steps.h5'\n",
        "\n",
        "new_model = keras.models.load_model(drive_path + file_path + name)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_DB73L-708y",
        "colab_type": "text"
      },
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaW0U15tAhii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_clean(text):\n",
        "\n",
        "  splits = text.split(' . ')[:-1]\n",
        "\n",
        "  new_splits = []\n",
        "\n",
        "  for split in splits[1:]:\n",
        "\n",
        "    word_splits = split.split(' ')\n",
        "    \n",
        "    word_splits[0] = word_splits[0].capitalize()\n",
        "    \n",
        "    word_splits[-1] = ''.join([word_splits[-1], '.'])\n",
        "\n",
        "    joined = ' '.join(word_splits)\n",
        "\n",
        "    new_splits.append(joined)\n",
        "  \n",
        "  join_split = ' '.join(new_splits)\n",
        "\n",
        "  return join_split\n",
        "\n",
        "def preprocessor(text):\n",
        "\n",
        "  # X = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "  # return tf.one_hot(X, max_id) # for no embedding\n",
        "\n",
        "  # return tokenizer.texts_to_sequences(text) # for embedding\n",
        "\n",
        "def next_word(text, model, temperature=1):\n",
        "  \n",
        "  X_new = preprocessor([text])\n",
        "\n",
        "  y_proba = model.predict(X_new)[0, -1:, :]\n",
        "\n",
        "  rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "\n",
        "  word_id = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "\n",
        "  return tokenizer.sequences_to_texts(word_id.numpy())[0]\n",
        "\n",
        "def complete_text(text, model, n_words=50, temperature=0.5):\n",
        "\n",
        "  for _ in range(n_words):\n",
        "\n",
        "    space = [' ', next_word(text, model, temperature)]\n",
        "    \n",
        "    text += ''.join(space)\n",
        "\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sITGZHtLZfXT",
        "colab_type": "code",
        "outputId": "8ff87c58-0f0b-4561-e57b-b9766655d0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "key_words = ['fcra', 'loan', 'bank', 'equifax breach', 'credit card', 'credit report']\n",
        "\n",
        "temps = [0.15, 0.2, 0.25]\n",
        "\n",
        "count = 0\n",
        "\n",
        "for key_word in key_words:\n",
        "  for temp in temps:\n",
        "    count += 1\n",
        "    print(f'{count} (kw: \"{key_word}\", tmp: {temp})', text_clean(complete_text(key_word, new_model_2, temperature=temp)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 (kw: \"fcra\", tmp: 0.15) I have been disputing this debt with transunion and i have never received any response from the provider of service. I have been disputing the pmi with the credit bureaus. I have been disputing this account with the credit bureaus.\n",
            "2 (kw: \"fcra\", tmp: 0.2) I have been disputing this account with bsi financial services. I have been disputing this account with my credit report. I have been disputing this debt with the credit bureaus. I have been disputing this debt from my credit report.\n",
            "3 (kw: \"fcra\", tmp: 0.25) I have contacted them about the process of the phone with the company and that my credit score is now. I have been trying to obtain a home and they have not been able to do so. I am not sure what happened to the.\n",
            "4 (kw: \"loan\", tmp: 0.15) I was told that the check was rejected by seterus,. Inc. I was told that the check had bounced. I was told that the check was rejected by the bank of america.\n",
            "5 (kw: \"loan\", tmp: 0.2) I have been a victim of identity theft and i have never received any response from the provider of service. I have been disputing this debt with my credit report. I have been disputing this debt with the credit bureaus.\n",
            "6 (kw: \"loan\", tmp: 0.25) I was told that i was a victim of identity theft. I have been disputing this account with my credit report. I have been disputing this debt on my credit report and i have never received a response from the company.\n",
            "7 (kw: \"bank\", tmp: 0.15) I was told that the check was rejected by the bank of america. I was told that the check had bounced. I was told that the check was not mine.\n",
            "8 (kw: \"bank\", tmp: 0.2) I was told that the check was rejected by the bank of america. I was told that the payment was rejected by the bank of america. I was told that the check was accepted and i was told that the check was rejected.\n",
            "9 (kw: \"bank\", tmp: 0.25) I was told that the check was rejected by the bank of america. I was told that the check was rejected by the bank of america preferred line and i was told that the check was rejected.\n",
            "10 (kw: \"equifax breach\", tmp: 0.15) I am requesting immediate removal of the debt. I have been disputing this account with my credit report and i have been disputing this debt. I have been disputing this account with transunion.\n",
            "11 (kw: \"equifax breach\", tmp: 0.2) I have been disputing this account with my credit report. I have been disputing this account with the credit bureaus. I have been disputing this debt from my credit report.\n",
            "12 (kw: \"equifax breach\", tmp: 0.25) I have been disputing the pmi with the company that i am not able to obtain a new credit card holder. I have never received any communication from the company. I have been disputing the pmi with.\n",
            "13 (kw: \"credit card\", tmp: 0.15) But he was going to collect a debt. I was told that the check was rejected by the bank. I was told that the check was rejected by the bank. I was told that the check was rejected by the bank of america.\n",
            "14 (kw: \"credit card\", tmp: 0.2) I have been disputing the pmi. I have been disputing this account with. I have never received anything from the company. I have no idea what i can do with this company.\n",
            "15 (kw: \"credit card\", tmp: 0.25) I have been trying to get a letter from the company. I have never been able to get a response from them. I have been disputing this account with my credit report.\n",
            "16 (kw: \"credit report\", tmp: 0.15) I have been disputing the pmi. I have been disputing this account with the credit bureaus. I have been disputing this debt from my credit report. I have never been able to obtain a new credit report.\n",
            "17 (kw: \"credit report\", tmp: 0.2) I have never received any response from the provider of service. I have been disputing the pmi with the company and they have refused to remove this account.\n",
            "18 (kw: \"credit report\", tmp: 0.25) I have been disputing this account with them. I have been disputing the pmi. I have been trying to resolve this issue with the company to remove this account. I have been trying to resolve this issue.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}